x=c(3,4,6,7)
x
x[2]
rm(list = ls())
dev.off()
library("ISLR")
library("MASS")
autop = read.csv("Auto.csv")
autop = read.csv("ISLR"$"Auto.csv")
?::
autop = ISLR::Auto
rm(list = ls())
autop = ISLR::Auto
library("ISLR")
library("MASS")
attach(autop)
?elseif
## 11 (a)
## create a binary variable that contains 1 if mpg>median and 0 if mpg<median
mpg01 = as.factor(mpg, ordered = F, levels = c(0,1))
class(mpg01)
## 11 (a)
## create a binary variable that contains 1 if mpg>median and 0 if mpg<median
mpg01 = factor(mpg, ordered = F, levels = c(0,1))
class(mpg01)
mpg01 = ifelse(mpg>median(mpg), 1, 0)
autop = data.frame(autop,mpg01)
summary(autop)
fix(autop)
pairs(autop, lower.panel = NULL)
boxplot(mpg01~horsepower, data = autop)
boxplot(horsepower~mpg01, data = autop)
names(autop)
boxplot(autop[, -9:-10]~mpg01, data = autop)
autop[, -9:-10]
autop[1, -9:-10]
boxplot(autop[, -9:-10]~mpg01, data = autop)
variable
names(autop)
boxplot(mpg~mpg01, data = autop)
boxplot(cylinders~mpg01, data = autop)
boxplot(displacement~mpg01, data = autop)
boxplot(displacement~mpg01, data = autop)
boxplot(cylinders~mpg01, data = autop)
boxplot(horsepower~mpg01, data = autop)
boxplot(weight~mpg01, data = autop)
boxplot(acceleration~mpg01, data = autop)
boxplot(year~mpg01, data = autop)
boxplot(origin~mpg01, data = autop)
boxplot(mpg~mpg01, data = autop)
cor(autop)
cor(,10)
cor(autop[,-9])
class(autop)
class(autop$cylinders)
class(autop$name)
pairs(autop, lower.panel = NULL)
## mpg01 is a direct product of mpg.
## Since horsepower, weight, displacement, and acceleration features affect mpg, they affect mpg01 as well.
## We boxplot mpg and each of these feature to investigate how they might affect mpg01
boxplot(horsepower~mpg, data = autop)
## mpg01 is a direct product of mpg.
## Since horsepower, weight, displacement, and acceleration features affect mpg, they affect mpg01 as well.
## We boxplot mpg and each of these feature to investigate how they might affect mpg01
boxplot(mpg~horsepower, data = autop)
## mpg01 is a direct product of mpg.
## Since horsepower, weight, displacement, and acceleration features affect mpg, they affect mpg01 as well.
## We boxplot mpg and each of these feature to investigate how they might affect mpg01
boxplot(mpg~horsepower, data = autop)
boxplot(mpg~weight, data = autop)
boxplot(mpg~displacement, data = autop)
boxplot(mpg~acceleration, data = autop)
## mpg01 is a direct product of mpg.
## Since horsepower, weight, displacement, and acceleration features affect mpg, they affect mpg01 as well.
## We boxplot mpg and each of these feature to investigate how they might affect mpg01
boxplot(horsepower~mpg, data = autop)
boxplot(horsepower~mpg, data = autop)
boxplot(mpg~weight, data = autop)
boxplot(mpg~displacement, data = autop)
boxplot(mpg~acceleration, data = autop)
boxplot(mpg~weight, data = autop, varwidth = T)
cor(autop)
cor(,10)
boxplot(horsepower~mpg, data = autop)
boxplot(mpg~displacement, data = autop)
boxplot(horsepower~mpg01, data = autop)
boxplot(mpg~weight, data = autop, varwidth = T)
boxplot(mpg01~weight, data = autop, varwidth = T)
boxplot(weight~mpg01, data = autop, varwidth = T)
boxplot(displacement~mpg, data = autop)
boxplot(displacement~mpg01, data = autop)
boxplot(acceleration~mpg01, data = autop)
boxplot(horsepower~mpg01, data = autop)
boxplot(weight~mpg01, data = autop)
boxplot(displacement~mpg01, data = autop)
boxplot(weight~mpg01, data = autop)
pairs(autop, lower.panel = NULL)
boxplot(horsepower~mpg01, data = autop)
boxplot(weight~mpg01, data = autop)
boxplot(displacement~mpg01, data = autop)
boxplot(acceleration~mpg01, data = autop)
boxplot(horsepower~mpg01, data = autop)
boxplot(weight~mpg01, data = autop)
boxplot(displacement~mpg01, data = autop)
# PAIRWISE MATRIX PLOT EXCLUDING MPG AND NAME
pairs(Auto_local[, c(-1, -2,-8,-9, -10)], lower.panel = NULL)
# PAIRWISE MATRIX PLOT EXCLUDING MPG AND NAME
pairs(autop[, c(-1, -2,-8,-9, -10)], lower.panel = NULL)
pairs(autop, lower.panel = NULL)
Auto_local = Auto
attach(Auto_local)
mpg01 = factor(mpg, ordered = F, levels = c(0,1))
mpg01 = ifelse(mpg>median(mpg), 1, 0)
Auto_local = data.frame(Auto_local,mpg01)
summary(Auto_local)
pairs(Auto_local, lower.panel = NULL)
ioio = c(1,2,3)
?floor()
floor(ioio)
ceiling(ioio)
floor(autop)
floor(1231)
ceiling(1231)
floor(12.5)
ceiling(12.4)
floor(12.9)
trunc(12.9)
floor(-12.1)
trunc(-12.1)
ioio = c(12, -1.4, 4,1, -4.1, -11.2, 2.3)
floor(ioio)
smp_siz = 0.75*nrow(autop)
smp_siz
summary(smp_siz)
?sample()
?sample()
training = sample(autop, size = 0.5*autop, replace = F, prob = NULL)
training = sample(autop, size = 392/2, replace = F, prob = NULL)
training = sample(autop, size = 196, replace = F, prob = NULL)
training = sample(autop, 196, replace = F, prob = NULL)
trn = sample(autop, 150)
trn = sample.int(autop, size = 196, replace = F, prob = NULL)
trn = sample.int(196, size = 196, replace = F, prob = NULL)
summary(trn)
?sample.split
??sample.split
??sample.split
smp_siz = floor(0.75*nrow(Smarket))
?floor
smp_siz = trunc(0.5*nrow(autop))
?sample
sample_size = trunc(0.5*nrow(autop))
rm(smp_siz)
sample_size = trunc(0.80*nrow(autop))
?seq_len
rm(ioio)
rm(trn)
set.seed(1)
num_train <- nrow(Auto_local) * 0.75
inTrain <- sample(nrow(Auto_local), size = num_train)
?inTrain
??inTrain
class(inTrain)
?sample
num_train = nrow(Auto_local) * 0.75
?nrow
training = Auto_local[inTrain,]
testing = Auto_local[-inTrain,]
class(training)
training
testing
Auto_local[,2]
sum(Auto_local$cylinders = 3)
sum(Auto_local$cylinders == 3)
sum(Auto_local$cylinders == 5)
class(inTrain)
library("MASS")
fmla = as.formula('mpg01 ~ displacement + horsepower + weight + year + cylinders')
class(fmla)
?formula
lda_model <- lda(fmla, data = training)
?lda
lda_pred <- predict(lda_model, testing)
table(lda_pred$class, testing$mpg01)
?table
class(lda_model)
fix(lda_model)
1 - mean(lda_pred$class == testing$mpg01)
da_model = qda(fmla, data = training)
qda_model = qda(fmla, data = training)
rm(da_model)
qda_pred <- predict(qda_model, testing)
table(qda_pred$class, testing$mpg01)
1 - mean(qda_pred$class == testing$mpg01)
log_reg <- glm(fmla, data = training, family = binomial)
?glm
pred <- predict(log_reg, testing, type = 'response')
pred_values <- round(pred)
table(pred_values, testing$mpg01)
1- mean(pred_values == testing$mpg01)
?par
par
rnorm(10,10,1)
rnorm(10,10,1)
rnorm(10,10,1)
set.seed(222)
rnorm(10,10,1)
rnorm(10,10,1)
set.seed(222)
rnorm(10,10,1)
?lda
table(lda_pred$class, testing$mpg01)
lda_pred
head(lda_pred)
lda_pred[1,]
lda_pred$class[1:3]
?predict
class(lda_model)
class(lda_pred)
lda_pred
table(lda_pred$class, testing$mpg01)
num_train = nrow(Auto_local) * 0.80
inTrain = sample(nrow(Auto_local), size = num_train)
training = Auto_local[inTrain,]
testing = Auto_local[-inTrain,]
fmla = as.formula('mpg01 ~ displacement + horsepower + weight + year + cylinders')
lda_model <- lda(fmla, data = training)
lda_pred <- predict(lda_model, testing)
table(lda_pred$class, testing$mpg01)
num_train = nrow(Auto_local) * 0.85
inTrain = sample(nrow(Auto_local), size = num_train)
training = Auto_local[inTrain,]
testing = Auto_local[-inTrain,]
fmla = as.formula('mpg01 ~ displacement + horsepower + weight + year + cylinders')
class(fmla)
lda_model <- lda(fmla, data = training)
lda_pred <- predict(lda_model, testing)
table(lda_pred$class, testing$mpg01)
num_train = nrow(Auto_local) * 0.98
inTrain = sample(nrow(Auto_local), size = num_train)
training = Auto_local[inTrain,]
testing = Auto_local[-inTrain,]
fmla = as.formula('mpg01 ~ displacement + horsepower + weight + year + cylinders')
class(fmla)
lda_model <- lda(fmla, data = training)
lda_pred <- predict(lda_model, testing)
table(lda_pred$class, testing$mpg01)
?glm
log_reg <- glm(fmla, data = training, family = binomial)
?predict
pred <- predict(log_reg, testing, type = 'response')
pred
pred_values <- round(pred)
pred_values
fmla <- as.formula('as.factor(mpg01) ~ displacement + horsepower + weight + year + cylinders')
log_reg <- glm(fmla, data = training, family = binomial)
pred <- predict(log_reg, testing, type = 'response')
pred
pred_values <- round(pred)
pred_values
num_train = nrow(Auto_local) * 0.75
num_train = nrow(Auto_local) * 0.75
inTrain = sample(nrow(Auto_local), size = num_train)
training = Auto_local[inTrain,]
testing = Auto_local[-inTrain,]
fmla <- as.formula('as.factor(mpg01) ~ displacement + horsepower + weight + year + cylinders')
log_reg <- glm(fmla, data = training, family = binomial)
pred <- predict(log_reg, testing, type = 'response')
pred_values <- round(pred)
pred_values
table(pred_values, testing$mpg01)
table(pred_values, testing$mpg01)
predict(round(pred$class), testing$mpg01)
pred
table(pred_values, testing$mpg01)
qda_pred
?knn
install.packages(e1701)
install.packages("e1701")
install.packages("LiblineaR")
install.packages("e1701")
updateR()
?installr
?installR
suppressMessages(library(randomForest))
library(gbm)
library(tree)
install.packages("e1071")
library(e1071)
?svm()
set.seed(999)
x = matrix(rnorm(20*2), ncol = 2)
y = c(rep(-1,10), rep(1,10))
?rep()
x[y==1,] = x[y==1,]+1
plot(x, col = (3-y) )
?rnorm
x
y
dat = data.frame(x=x, y=as.factor(y))
svmfit = svm(y~., data = dat, kernel = "linear", cost=10, scale = F)
plot(svmfit, dat)
svmfit$index
summary(svmfit)
svmfit
svmfit = svm(y~., data = dat, kernel = "linear", cost=0.1, scale = F)
plot(svmfit, dat)
svmfit$index
rm(list = ls())
dev.off()
suppressMessages(library(randomForest))
library(gbm)
library(tree)
nba = read.csv("CIS_HW4.csv")
setwd("C:/Users/elais/Desktop/Code/Bob-cis3920/Group_Home_Work_04")
nba = read.csv("CIS_HW4.csv")
names(nba)
nba = nba[,-c(1,2,3,7,11,14,17,18,21)]
attach(nba)
nba = nba[nba$MP>6, ]
colSums(is.na(nba))
set.seed(8)
train_nba = sample(1:nrow(nba), nrow(nba)/2)
boost_nba = gbm(PTS~.-Tm, data = nba[train_nba,], distribution = "gaussian", n.trees = 5000, interaction.depth = 4)
summary(boost_nba)
par(mfrow = c(1,1))
par(mfrow = c(2,2))
plot(boost_nba, i="FG")
plot(boost_nba, i="FGA")
yhat.boost = predict(boost_nba, newdata = nba[-train_nba,], n.trees = 5000)
mean((yhat.boost - nba[-train_nba ,"PTS" ])^2)
bag_nba = randomForest(PTS~.-Tm ,data = nba, subset = train_nba, mtry = 19, importance = T)
yhat.bag = predict(bag_nba, newdata = nba[-train_nba,])
plot(yhat.bag, nba[-train_nba,"PTS"])
abline(0,1, col = 5)
mean((yhat.bag - nba[-train_nba ,"PTS" ])^2)
tree_nba = tree(PTS~.-Tm, nba , subset = train_nba)
summary(tree_nba)
plot(tree_nba)
text(tree_nba, pretty = 0)
cv_nba = cv.tree(tree_nba)
plot(cv_nba$size, cv_nba$dev, type = 'b')
cv_nba
pruning_nba = prune.tree(tree_nba, best = 8)
plot(pruning_nba)
text(pruning_nba, pretty = 0)
yhat.tree = predict(tree_nba, newdata = nba[-train_nba,])
plot(yhat.tree, nba[-train_nba,"PTS"])
abline(0,1, col = 5)
mean((yhat.tree-nba[-train_nba,"PTS"])^2)
# applying multiple linear regression
par(mfrow = c(2,2))
lm_nba = lm(PTS~.-Tm, nba, subset = train_nba)
plot(lm_nba)
par(mfrow = c(1,1))
plot(lm_nba)
plot(lm_nba)
?plot.lm
train_nba[57,]
summary(train_nba)
class(train_nba)
train_nba[57]
nba[287,]
plot(lm_nba, which = 5, caption = T)
plot(lm_nba)
?plot.lm
# applying multiple linear regression
par(mfrow = c(2,2))
lm_nba = lm(PTS~.-Tm, nba, subset = train_nba)
plot(lm_nba)
?plot.lm
identify()
plot(lm_nba, which = 5, caption = T, id.n = 7)
plot(lm_nba, which = 5, caption = T, id.n = 12)
plot(lm_nba, which = 5, caption = T, id.n = 12)
train_nba_lm = train_nba[-c(57, 422)]
train_nba[422]
nba[57]
nba[57,]
nba[422,]
train_nba["422"]
train_nba[train_nba>400]
plot(lm_nba)
train_nba
train_nba[train_nba_lm==422]
?lm()
lm_nba = lm(PTS~.-Tm, nba[train_nba])
lm_nba = lm(PTS~.-Tm, nba[train_nba,])
plot(lm_nba)
summary(lm_nba)
train_nba_lm = train_nba[-c("57", "422")]
train_nba[train_nba==57]
train_nba[train_nba==422]
?plot.lm
plot(lm_nba, which = 5, caption = T, id.n = 12)
plot(lm_nba, which = 5, caption = T, id.n = 12, labels.id = NULL)
plot(lm_nba, id.n = 12, labels.id = NULL)
train_nba_lm = train_nba[-c(14,42),]
train_nba_lm = train_nba[-c(14,42)]
lm_nba_2 = lm(PTS~.-Tm, nba[train_nba_lm,])
plot(lm_nba_2)
lm_nba.predict_2 = predict(lm_nba_2, newdata = nba[-train_nba_lm,])
mean((lm_nba.predict_2-nba[-train_nba_lm,"PTS"])^2)
?glm()
log_nba = glm(PTS~.-Tm, data = nba[train_nba,])
yhat.log = predict(log_nba, newdata = nba[-train_nba])
yhat.log = predict(log_nba, newdata = nba[-train_nba,])
plot(yhat.log, nba[-train_nba,"PTS"])
abline(0,1, col = 7)
abline(0,1, col = 8)
abline(0,1, col = 12)
abline(0,1, col = 5)
mean((yhat.log - nba[-train_nba ,"PTS" ])^2)
